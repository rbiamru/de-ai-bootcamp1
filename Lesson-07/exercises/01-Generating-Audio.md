# Extending the Chef GPT App with Text to Speech

1. Open the Chef GPT page we created in the last exercise on your IDE

2. Create a button to generate audio instructions for the recipes

   - Similar to the image generation button, create `audioIsLoading` and `audio` state variables by adding the following code after the last `useState` definition at the top of the code

     ```tsx
     const [audioIsLoading, setAudioIsLoading] = useState(false);
     const [audio, setAudio] = useState<string | null>(null);
     ```

   - Add a button to generate audio instructions for the recipe inside the image return statement. Place it after the `textarea` tag

     ```tsx
     <div className="flex flex-col justify-center mb-2 items-center">
       {!audioIsLoading && !audio && (
         <button
           className="bg-blue-500 p-2 text-white rounded shadow-xl"
           onClick={() => {}}
         >
           Generate Audio
         </button>
       )}
     </div>
     ```

   - After adding the code, the `return` statement should look like this:

   ```tsx
   if (image) {
     return (
       <div className="flex flex-col p-4 justify-center gap-4 h-screen">
         <img src={`data:image/jpeg;base64,${image}`} />
         <textarea
           className="mt-4 w-full text-white bg-black h-64"
           value={messages[messages.length - 1].content}
           readOnly
         />

         <div className="flex flex-col justify-center mb-2">
           {!audioIsLoading && !audio && (
             <button
               className="bg-blue-500 p-2 text-white rounded shadow-xl"
               onClick={() => {}}
             >
               Generate Audio
             </button>
           )}
         </div>
       </div>
     );
   }
   ```

3. The button should set the `audioIsLoading` state to `true` while the audio is being generated

   - Modify the `onClick` event of the button to add a call to the `setAudioIsLoading` function

     ```tsx
     onClick={() => {
       setAudioIsLoading(true);
       // TODO
       setAudioIsLoading(false);
     }}
     ```

   - Add a conditional rendering to show a loading message while the audio is being generated

     ```tsx
     {
       audioIsLoading && !audio && <p> Audio is being generated... </p>;
     }
     ```

   - After adding the code, the `return` statement should look like this:

     ```tsx
     if (image) {
       return (
         <div className="flex flex-col p-4 justify-center gap-4 h-screen">
           <img src={`data:image/jpeg;base64,${image}`} />
           <textarea
             className="mt-4 w-full text-white bg-black h-64"
             value={messages[messages.length - 1].content}
             readOnly
           />

           <div className="flex flex-col justify-center mb-2">
             {audioIsLoading && !audio && <p> Audio is being generated... </p>}
             {!audioIsLoading && !audio && (
               <button
                 className="bg-blue-500 p-2 text-white rounded shadow-xl"
                 onClick={() => {
                   setAudioIsLoading(true);
                   // TODO
                   setAudioIsLoading(false);
                 }}
               >
                 Generate Audio
               </button>
             )}
           </div>
         </div>
       );
     }
     ```

4. When the user clicks the button, the app should call the OpenAI API to generate an audio file from the recipe in the text area

   - Create a new folder named `audio` under the `api` folder

   - Add a file named `route.ts` inside the `audio` folder

   - Include the following code in the `route.ts` file:

     ```ts
     import { NextResponse } from "next/server";
     import OpenAI from "openai";

     const openai = new OpenAI({
       apiKey: process.env.OPENAI_API_KEY,
     });

     export const runtime = "edge";

     export async function POST(req: Request) {
       const { message } = await req.json();
       const response = await openai.audio.speech.create({
         model: "tts-1",
         voice: "alloy",
         input: message,
       });
       return new NextResponse(response.body);
     }
     ```

5. Stream the audio file generated by the OpenAI API to the user

   - Update the `onClick` event of the `Generate Audio` button to call the API and set the audio state with the response

     ```tsx
     onClick={async () => {
       setAudioIsLoading(true);
       const response = await fetch("/api/audio", {
         method: "POST",
         headers: {
           "Content-Type": "application/json",
         },
         body: JSON.stringify({
           message: messages[messages.length - 1].content,
         }),
       });
       const audioBlob = await response.blob();
       const audioUrl = URL.createObjectURL(audioBlob);
       setAudio(audioUrl);
       setAudioIsLoading(false);
     }}
     ```

6. Provide the user with a link to play/download the audio file when it's ready

   - Add other conditional rendering before the loading message conditional rendering from step 3. This will show the audio player when the audio is ready

     ```tsx
     {
       audio && (
         <>
           <p> Listen to the recipe: </p>
           <audio controls src={audio} className="w-full"></audio>
         </>
       );
     }
     ```

7. Check the code for the audio generation and rendering in the browser

   - The `return` statement for the component after the image was generated should look like this:

     ```tsx
     if (image) {
       return (
         <div className="flex flex-col p-4 justify-center gap-4 h-screen">
           <img src={`data:image/jpeg;base64,${image}`} />
           <textarea
             className="mt-4 w-full text-white bg-black h-64"
             value={messages[messages.length - 1].content}
             readOnly
           />

           <div className="flex flex-col justify-center mb-2">
             {audio && (
               <>
                 <p> Listen to the recipe: </p>
                 <audio controls src={audio} className="w-full"></audio>
               </>
             )}
             {audioIsLoading && !audio && <p> Audio is being generated... </p>}
             {!audioIsLoading && !audio && (
               <button
                 className="bg-blue-500 p-2 text-white rounded shadow-xl"
                 onClick={async () => {
                   setAudioIsLoading(true);
                   const response = await fetch("/api/audio", {
                     method: "POST",
                     headers: {
                       "Content-Type": "application/json",
                     },
                     body: JSON.stringify({
                       message: messages[messages.length - 1].content,
                     }),
                   });
                   const audioBlob = await response.blob();
                   const audioUrl = URL.createObjectURL(audioBlob);
                   setAudio(audioUrl);
                   setAudioIsLoading(false);
                 }}
               >
                 Generate Audio
               </button>
             )}
           </div>
         </div>
       );
     }
     ```

8. Run the app by executing the following command in the terminal:

   ```bash
   npm run dev
   ```

9. Test the audio generation feature by requesting a recipe and clicking the "Generate Audio" button

   - Now you can cook the recipes while away from the computer by listening to the audio instructions

   - Always remember to check anything AI generated before following it to ensure it makes sense and is safe to use
